
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <meta name="viewport" content="width=device-width, initial-scale=1.0">
            <link rel="icon" type="image/png" href="../assets/favicon.png">
            <title>AIæ–°é—»æ‘˜è¦</title>
            
        <style>
            :root {
                --primary-color: #4a4a4a;
                --secondary-color: #0066cc;
                --background-color: #f4f4f4;
                --card-background: #ffffff;
            }
            body {
                font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
                background-color: var(--background-color);
                color: var(--primary-color);
                margin: 0;
                padding: 0;
                line-height: 1.6;
                transition: background-color 0.3s, color 0.3s;
            }
            .container {
                max-width: 800px;
                margin: 0 auto;
                padding: 20px;
                position: relative;
                z-index: 1;
                background: rgba(244, 244, 244, 0.9);
                border-radius: 15px;
                backdrop-filter: blur(10px);
                -webkit-backdrop-filter: blur(10px);
                margin: 20px auto;
                padding: 20px;
            }
            header {
                background-color: var(--secondary-color);
                color: white;
                text-align: center;
                padding: 1em;
                position: relative;
                z-index: 1;
                background: rgba(0, 102, 204, 0.9);
                backdrop-filter: blur(10px);
                -webkit-backdrop-filter: blur(10px);
            }
            h1 {
                margin: 0;
            }
            h2 {
                color: var(--secondary-color);
                border-bottom: 2px solid var(--secondary-color);
                padding-bottom: 10px;
                margin-top: 30px;
            }
            .card {
                background-color: var(--card-background);
                border-radius: 8px;
                box-shadow: 0 2px 4px rgba(0,0,0,0.1);
                margin-bottom: 20px;
                padding: 20px;
                transition: transform 0.3s ease;
                background: rgba(255, 255, 255, 0.9);
                backdrop-filter: blur(5px);
                -webkit-backdrop-filter: blur(5px);
            }
            .card:hover {
                transform: scale(1.05);
            }
            .card h3 {
                color: var(--secondary-color);
                margin-top: 0;
            }
            a {
                color: var(--secondary-color);
                text-decoration: none;
            }
            a:hover {
                text-decoration: underline;
            }
            .emoji {
                font-size: 1.5em;
                margin-right: 5px;
            }
            footer {
                text-align: center;
                margin-top: 40px;
                padding: 20px;
                background-color: var(--secondary-color);
                color: white;
                position: relative;
                z-index: 1;
                background: rgba(0, 102, 204, 0.9);
                backdrop-filter: blur(10px);
                -webkit-backdrop-filter: blur(10px);
            }
            @media (max-width: 600px) {
                .container {
                    padding: 10px;
                }
            }
            
            /* æš—é»‘æ¨¡å¼æ ·å¼ */
            body.dark-mode {
                --primary-color: #e0e0e0;
                --secondary-color: #4da6ff;
                --background-color: #2c2c2c;
                --card-background: #3c3c3c;
            }
            body.dark-mode .container {
                background: rgba(44, 44, 44, 0.9);
            }
            body.dark-mode .card {
                background: rgba(60, 60, 60, 0.9);
            }
            body.dark-mode header,
            body.dark-mode footer {
                background: rgba(26, 26, 26, 0.9);
            }
            #darkModeToggle {
                background-color: var(--secondary-color);
                color: white;
                border: none;
                padding: 10px 20px;
                border-radius: 5px;
                cursor: pointer;
                transition: background-color 0.3s;
            }
            #darkModeToggle:hover {
                background-color: #0052a3;
            }
            
            /* æ–°å¢çš„åŠ¨ç”»å’Œäº¤äº’æ ·å¼ */
            @keyframes wave {
                50% { rotate: 10deg; }
            }
            
            @keyframes hover {
                from, to { translate: 0 -5%; }
                50% { translate: 0 5%; }
            }
            
            .intro {
                display: flex;
                justify-content: center;
                gap: 0.2em;
                font-size: 2em;
                margin-top: 20px;
            }
            
            .intro span {
                display: inline-block;
            }
            
            .intro span:first-child {
                transform-origin: right bottom;
                animation: wave 250ms 1s ease 3;
            }
            
            .intro span:last-child {
                animation: hover 500ms linear infinite;
            }
            
            @keyframes fadeIn {
                from { opacity: 0; }
                to { opacity: 1; }
            }
            
            .fade-in {
                animation: fadeIn 1s ease-out;
            }
        </style>
        
            
        <script type="x-shader/x-fragment">#version 300 es
        precision highp float;
        out vec4 O;
        uniform float time;
        uniform vec2 resolution;
        #define FC gl_FragCoord.xy
        #define R resolution
        #define T time
        #define hue(a) (.6+.6*cos(6.3*(a)+vec3(0,83,21)))
        float rnd(float a) {
            vec2 p=fract(a*vec2(12.9898,78.233)); p+=dot(p,p*345.);
            return fract(p.x*p.y);
        }
        vec3 pattern(vec2 uv) {
            vec3 col=vec3(0);
            for (float i=.0; i++<20.;) {
                float a=rnd(i);
                vec2 n=vec2(a,fract(a*34.56)), p=sin(n*(T+7.)+T*.5);
                float d=dot(uv-p,uv-p);
                col+=.00125/d*hue(dot(uv,uv)+i*.125+T);
            }
            return col;
        }
        void main(void) {
            vec2 uv=(FC-.5*R)/min(R.x,R.y);
            vec3 col=vec3(0);
            float s=2.4,
            a=atan(uv.x,uv.y),
            b=length(uv);
            uv=vec2(a*5./6.28318,.05/tan(b)+T);
            uv=fract(uv)-.5;
            col+=pattern(uv*s);
            O=vec4(col,1);
        }</script>
        
        </head>
        <body>
            <header>
                <h1>ğŸš€ AIæ–°é—»æ‘˜è¦ ğŸ¤–</h1>
                <button id="darkModeToggle" onclick="toggleDarkMode()">åˆ‡æ¢åˆ°æš—è‰²æ¨¡å¼</button>
            </header>
            <div class="intro" aria-label="å‘ä¸‹æ»šåŠ¨æŸ¥çœ‹æ›´å¤š">
                <span>ğŸ‘‹</span>
                <span>â¬‡ï¸</span>
            </div>
            <div class='container'><div class='card'><h2>AI's Galactic Showdown: LocalLLama's Tech Extravaganza ğŸŒŒğŸ¦„</h2>
<p>Imagine a cosmic circus where AI models are the star performers, and the LocalLLama subreddit is their grand stage. ğŸªğŸ¤– Picture this: pint-sized AI models wowing the crowd on the MMLU-Pro stage, TTS models zooming past in a digital derby, and Intel Arrow Lake processors flexing their silicon biceps like digital bodybuilders. ğŸ‹ï¸â€â™‚ï¸ğŸ’¾ It's a tech carnival of innovation, and you're about to grab a front-row seat to the spectacle! ğŸŒŸğŸ‘€</p>
</div><div class='card'><h2>1. MMLU-Pro Scores of Small Models (&lt;5B) ğŸ“š</h2>
<ul>
<li>Reddit: <a href="https://www.reddit.com/r/LocalLLaMA/comments/1gihnet/what_happened_to_llama_32_90bvision/">Link</a></li>
<li>Facts: In the battle of the brains, Qwen2.5 and llama3.2 outshine their Phi counterparts, but MMLU might not be their ideal playground.</li>
<li>Personal thoughts: It's like watching David and Goliath, but in the AI arena! These small wonders are proving size isn't everything.</li>
<li>Description: These compact champions are shaking up the industry by challenging the "bigger is better" mantra.</li>
<li>Help for users: If you're a fan of mighty mini-AIs, keep your eyes peeled for Qwen2.5 and llama3.2!</li>
</ul>
</div><div class='card'><h2>2. Latency Analysis of TTS Models ğŸ¤</h2>
<ul>
<li>Reddit: <a href="https://www.reddit.com/r/LocalLLaMA/comments/1gindy1/looks_like_intel_arrow_lake_can_support_4_dimms/">Link</a></li>
<li>Facts: Tortoise TTS crawls at a snail's pace, while Piper TTS, MeloTTS, and XTTS-v2 zip along like cheetahs.</li>
<li>Personal thoughts: In the TTS sprint, speed is king, and some models are hitting the turbo button.</li>
<li>Description: This analysis is rewriting the rules of TTS efficiency, offering users swift and responsive options.</li>
<li>Help for users: Need lightning-fast TTS? Look no further than Piper, MeloTTS, or XTTS-v2.</li>
</ul>
</div><div class='card'><h2>3. Intel Arrow Lake and Memory Support ğŸ’¾</h2>
<ul>
<li>Reddit: <a href="https://www.reddit.com/r/LocalLLaMA/comments/1gihnet/what_happened_to_llama_32_90bvision/">Link</a></li>
<li>Facts: Arrow Lake can juggle 4 DIMMs with lightning speed, but bandwidth bottlenecks lurk.</li>
<li>Personal thoughts: It's like giving a sports car a tiny fuel tankâ€”impressive but problematic.</li>
<li>Description: This development could be a game-changer for large language models, if bandwidth issues don't spoil the party.</li>
<li>Help for users: Future-proof your rig, but keep an eye on those bandwidth hiccups.</li>
</ul>
</div><div class='card'><h2>4. Llama 3.2 90b-vision ğŸªğŸ‘€</h2>
<ul>
<li>Reddit: <a href="https://www.reddit.com/r/LocalLLaMA/comments/1gihnet/what_happened_to_llama_32_90bvision/">Link</a></li>
<li>Facts: Taming this visual beast is no walk in the parkâ€”no llamaccp and clunky AWQ, bitsnbytes usage.</li>
<li>Personal thoughts: It's like trying to ride a unicorn without a saddleâ€”possible but painful.</li>
<li>Description: Despite the setup headaches, its presence on lmsys arena is a game-changer for vision tasks.</li>
<li>Help for users: Brave the setup trials for top-tier vision prowess.</li>
</ul>
</div><div class='card'><h2>5. Speaking with Local LLM ğŸ—£ï¸ğŸ¤–</h2>
<ul>
<li>Reddit: <a href="https://www.reddit.com/r/LocalLLaMA/comments/1giozl9/speaking_with_your_local_llm_with_a_key_press_on/">Link</a></li>
<li>Facts: Chat with your LLM at the press of a keyâ€”works on Linux and most desktops.</li>
<li>Personal thoughts: It's like having a chit-chat with HAL 9000, but less nightmare-inducing.</li>
<li>Description: This tool bridges the human-AI communication gap, making interactions smoother and more intuitive.</li>
<li>Help for users: Elevate your AI conversations with this nifty speech-to-text feature.</li>
</ul>
</div><div class='card'><h2>6. RAG Solutions ğŸ”„ğŸ“˜</h2>
<ul>
<li>Reddit: <a href="https://www.reddit.com/r/LocalLLaMA/comments/1giadgu/why_dont_any_of_the_big_ai_companies_support_a/">Link</a></li>
<li>Facts: Snorkel AI, Glean, and others dive into RAG, supercharging data labeling and indexing.</li>
<li>Personal thoughts: It's like giving AI a brain transplantâ€”smarter and more efficient.</li>
<li>Description: RAG is transforming how AI handles data, leading to more accurate and relevant outputs.</li>
<li>Help for users: Dive into RAG for a more intelligent AI experience.</li>
</ul>
</div><div class='card'><h2>7. Benchmarked 3090s for Optimized Power Configuration âš¡ğŸ®</h2>
<ul>
<li>Reddit: <a href="https://www.reddit.com/r/LocalLLaMA/comments/1gic7v1/benchmarked_3090s_to_find_the_most_optimized/">Link</a></li>
<li>Facts: TabbyAPI with EXL2 quantization wins the power efficiency race.</li>
<li>Personal thoughts: It's like discovering the golden key to unlock GPU performance without breaking the bank.</li>
<li>Description: This research is a godsend for GPU enthusiasts, offering a roadmap to optimal power settings.</li>
<li>Help for users: Fine-tune your 3090 for peak performance without the power drain.</li>
</ul>
</div><div class='card'><h2>8. tldw (Open Source NotebookLM) ğŸ““ğŸ”“</h2>
<ul>
<li>Reddit: <a href="https://www.reddit.com/r/LocalLLaMA/comments/1girn7t/tldw_open_source_notebooklm_sharing_a_tool_ive/">Link</a></li>
<li>Facts: Run NotebookLM locally on any OS, but podcast creation is still a no-go.</li>
<li>Personal thoughts: It's like having a DIY AI notebookâ€”powerful but a bit feature-light.</li>
<li>Description: tldw democratizes AI tool access, letting anyone dive into the world of LLMs.</li>
<li>Help for users: Get your hands on a versatile, open-source NotebookLM alternative.</li>
</ul>
</div><div class='card'><h2>9. M4 Max - 546GB/s ğŸš€ğŸ’¾</h2>
<ul>
<li>Reddit: <a href="https://www.reddit.com/r/LocalLLaMA/comments/1ghwdjy/m4_max_546gbs/">Link</a></li>
<li>Facts: M4 Max boasts mind-blowing memory bandwidth, outpacing M2 Ultra in efficiency.</li>
<li>Personal thoughts: It's like strapping a rocket to your laptopâ€”fast but consider the fuel (power).</li>
<li>Description: This processor is setting new performance benchmarks, especially for power-conscious users.</li>
<li>Help for users: If speed and efficiency are your game, M4 Max is your go-to.</li>
</ul>
</div><div class='card'><h2>10. Introducing CaSIL ğŸ§©ğŸ¤”</h2>
<ul>
<li>Reddit: <a href="https://www.reddit.com/r/LocalLLaMA/comments/1gi102k/introducing_cascade_of_semantically_integrated/">Link</a></li>
<li>Facts: CaSIL aims to boost AI thought/reasoning but is still short on benchmarks.</li>
<li>Personal thoughts: It's like trying to solve a Rubik's Cube blindfoldedâ€”promising but tricky.</li>
<li>Description: CaSIL could be a breakthrough in AI reasoning, if it can prove its worth.</li>
<li>Help for users: Keep an eye on CaSIL for potential advancements in AI thought processes.</li>
</ul>
</div><div class='card'><h2>11. Combining GOFAI with LLMs ğŸ¤–ğŸ”</h2>
<ul>
<li>Reddit: <a href="https://www.reddit.com/r/LocalLLaMA/comments/1gijddh/combining_gofai_with_llms/">Link</a></li>
<li>Facts: Marrying old-school AI with LLMs for smarter reasoning.</li>
<li>Personal thoughts: It's like blending a classic car engine with a modern electric motorâ€”retro-futuristic.</li>
<li>Description: This combo could unlock new levels of AI intelligence, merging logic with learning.</li>
<li>Help for users: Stay tuned for a potential revolution in AI reasoning capabilities.</li>
</ul>
</div><div class='card'><h2>12. Best Uncensored Long Context Model (128k) ğŸ“šğŸ”“</h2>
<ul>
<li>Reddit: <a href="https://www.reddit.com/r/LocalLLaMA/comments/1giicjl/best_ideally_uncensored_long_context_model_128k/">Link</a></li>
<li>Facts: Cohere, EVA Qwen, InternLM, Yi 200K shine, but uncensored models are a rarity.</li>
<li>Personal thoughts: It's like searching for a needle in a haystack, but the needle is super smart.</li>
<li>Description: These models are pushing the boundaries of context length, despite censorship challenges.</li>
<li>Help for users: Explore these models for unparalleled long-context capabilities.</li>
</ul>
</div><div class='card'><h2>13. Llama 3.1 70B Finetune Anecdotes ğŸªğŸ› ï¸</h2>
<ul>
<li>Reddit: <a href="https://www.reddit.com/r/LocalLLaMA/comments/1gi3l2q/llama_31_70b_finetune_anecdotes_on_production/">Link</a></li>
<li>Facts: Real-world tales of finetuning Llama 3.1 70B on production data.</li>
<li>Personal thoughts: It's like giving a master chef a new ingredient to play withâ€”exciting possibilities.</li>
<li>Description: These anecdotes highlight the practical applications and potential of large model fine-tuning.</li>
<li>Help for users: Gain insights from real-world use cases to inform your own fine-tuning endeavors.</li>
</ul>
</div><div class='card'><h2>14. Training Llama 4 on H100s ğŸªâš¡</h2>
<ul>
<li>Reddit: <a href="https://www.reddit.com/r/LocalLLaMA/comments/1giicjl/best_ideally_uncensored_long_context_model_128k/">Link</a></li>
<li>Facts: Llama 4 training on H100 GPUs sparks excitement and regulatory scrutiny.</li>
<li>Personal thoughts: It's like watching a superhero get a new suitâ€”expectations are sky-high.</li>
<li>Description: This training endeavor could lead to groundbreaking advancements, but with regulatory eyes watching.</li>
<li>Help for users: Keep an eye on Llama 4 for potential leaps in AI capabilities.</li>
</ul>
</div><div class='card'><h2>15. Current SOTA Model for Dependency Parsing ğŸŒ³ğŸ¤–</h2>
<ul>
<li>Reddit: <a href="https://www.reddit.com/r/LocalLLaMA/comments/1gim74q/current_sota_model_for_dependency_parsing/">Link</a></li>
<li>Facts: Models in the 3-8B range excel at parsing structured outputs.</li>
<li>Personal thoughts: It's like having a super-organized librarian for your dataâ€”efficient and precise.</li>
<li>Description: These models are setting new standards in dependency parsing, crucial for structured data tasks.</li>
<li>Help for users: Dive into these SOTA models for top-notch parsing capabilities.</li>
</ul>

<p>And there you have it, folks! ğŸ‰ğŸš€ From tiny AI models showing off their might to processors that could power a small galaxy, the LocalLLama subreddit is a goldmine of tech wonders. It's like watching a sci-fi epic unfold in real-time, where the heroes are algorithms and the plot is pure innovation. So, fasten your seatbelts and enjoy the ride, because the future is here, and it's absolutely mind-blowing! ğŸŒŸğŸ¤–ğŸˆ
```</p>

<hr />

<p>ç¨‹åºå¼€å§‹è¿è¡Œæ—¶é—´: 2024-11-04 01:12:56</p>

<hr />

<p>ç¨‹åºç»“æŸè¿è¡Œæ—¶é—´: 2024-11-04 01:17:51</p>

<hr />

<p>æ•´ä¸ªè¿è¡Œè¿‡ç¨‹ä½¿ç”¨äº† 295.36 ç§’.</p>

<hr />

<h2>æœ¬æ¬¡ç¨‹åºè¿è¡Œä½¿ç”¨çš„æ¨¡å‹: glm-4-plus</h2>
</div></div>
            <footer>
                <p>ç”Ÿæˆäº 2024-11-04 01:17:51</p>
            </footer>
            
        <script>
            function toggleDarkMode() {
                document.body.classList.toggle('dark-mode');
                const button = document.getElementById('darkModeToggle');
                if (document.body.classList.contains('dark-mode')) {
                    button.textContent = 'åˆ‡æ¢åˆ°äº®è‰²æ¨¡å¼';
                } else {
                    button.textContent = 'åˆ‡æ¢åˆ°æš—è‰²æ¨¡å¼';
                }
            }

            // å¹³æ»‘æ»šåŠ¨
            document.querySelectorAll('a[href^="#"]').forEach(anchor => {
                anchor.addEventListener('click', function (e) {
                    e.preventDefault();
                    document.querySelector(this.getAttribute('href')).scrollIntoView({
                        behavior: 'smooth'
                    });
                });
            });
            
            // æ–°å¢çš„åŠ¨ç”»æ•ˆæœå‡½æ•°
            function addFadeInEffect() {
                const cards = document.querySelectorAll('.card');
                const observer = new IntersectionObserver((entries) => {
                    entries.forEach(entry => {
                        if (entry.isIntersecting) {
                            entry.target.classList.add('fade-in');
                            observer.unobserve(entry.target);
                        }
                    });
                }, { threshold: 0.1 });
                
                cards.forEach(card => observer.observe(card));
            }
            
            // é¡µé¢åŠ è½½å®Œæˆåæ‰§è¡Œ
            window.addEventListener('load', addFadeInEffect);
        </script>
        
            
        <script>
        window.onload = init;
        function init() {
            let renderer, canvas;
            const dpr = Math.max(1, .5*devicePixelRatio);
            
            canvas = document.createElement("canvas");
            canvas.style.position = 'fixed';
            canvas.style.top = '0';
            canvas.style.left = '0';
            canvas.style.width = '100%';
            canvas.style.height = '100%';
            canvas.style.zIndex = '-1';
            document.body.insertBefore(canvas, document.body.firstChild);
            
            const resize = () => {
                const { innerWidth: width, innerHeight: height } = window;
                canvas.width = width * dpr;
                canvas.height = height * dpr;
                if (renderer) {
                    renderer.updateScale(dpr);
                }
            };
            
            const source = document.querySelector("script[type='x-shader/x-fragment']").textContent;
            canvas.style.userSelect = "none";
            renderer = new Renderer(canvas, dpr);
            renderer.setup();
            renderer.init();
            resize();
            if (renderer.test(source) === null) {
                renderer.updateShader(source);
            }
            window.onresize = resize;
            const loop = (now) => {
                renderer.render(now);
                requestAnimationFrame(loop);
            };
            loop(0);
        }
        
        class Renderer {
            #vertexSrc = "#version 300 es\nprecision highp float;\nin vec4 position;\nvoid main(){gl_Position=position;}";
            #fragmtSrc = "#version 300 es\nprecision highp float;\nout vec4 O;\nuniform float time;\nuniform vec2 resolution;\nvoid main() {\n\tvec2 uv=gl_FragCoord.xy/resolution;\n\tO=vec4(uv,sin(time)*.5+.5,1);\n}";
            #vertices = [-1, 1, -1, -1, 1, 1, 1, -1];
            
            constructor(canvas, scale) {
                this.canvas = canvas;
                this.scale = scale;
                this.gl = canvas.getContext("webgl2");
                this.gl.viewport(0, 0, canvas.width * scale, canvas.height * scale);
                this.shaderSource = this.#fragmtSrc;
                this.mouseCoords = [0, 0];
                this.pointerCoords = [0, 0];
                this.nbrOfPointers = 0;
            }

            get defaultSource() { 
                return this.#fragmtSrc;
            }

            updateShader(source) {
                this.reset();
                this.shaderSource = source;
                this.setup();
                this.init();
            }

            updateScale(scale) {
                this.scale = scale;
                this.gl.viewport(0, 0, this.canvas.width * scale, this.canvas.height * scale);
            }

            compile(shader, source) {
                const gl = this.gl;
                gl.shaderSource(shader, source);
                gl.compileShader(shader);
                if (!gl.getShaderParameter(shader, gl.COMPILE_STATUS)) {
                    console.error(gl.getShaderInfoLog(shader));
                }
            }

            test(source) {
                let result = null;
                const gl = this.gl;
                const shader = gl.createShader(gl.FRAGMENT_SHADER);
                gl.shaderSource(shader, source);
                gl.compileShader(shader);
                if (!gl.getShaderParameter(shader, gl.COMPILE_STATUS)) {
                    result = gl.getShaderInfoLog(shader);
                }
                gl.deleteShader(shader);
                return result;
            }

            reset() {
                const gl = this.gl;
                if (this.program) {
                    if (this.vs) {
                        gl.detachShader(this.program, this.vs);
                        gl.deleteShader(this.vs);
                    }
                    if (this.fs) {
                        gl.detachShader(this.program, this.fs);
                        gl.deleteShader(this.fs);
                    }
                    gl.deleteProgram(this.program);
                }
            }

            setup() {
                const gl = this.gl;
                this.vs = gl.createShader(gl.VERTEX_SHADER);
                this.fs = gl.createShader(gl.FRAGMENT_SHADER);
                this.compile(this.vs, this.#vertexSrc);
                this.compile(this.fs, this.shaderSource);
                this.program = gl.createProgram();
                gl.attachShader(this.program, this.vs);
                gl.attachShader(this.program, this.fs);
                gl.linkProgram(this.program);
            }

            init() {
                const gl = this.gl;
                this.buffer = gl.createBuffer();
                gl.bindBuffer(gl.ARRAY_BUFFER, this.buffer);
                gl.bufferData(gl.ARRAY_BUFFER, new Float32Array(this.#vertices), gl.STATIC_DRAW);
                const position = gl.getAttribLocation(this.program, "position");
                gl.enableVertexAttribArray(position);
                gl.vertexAttribPointer(position, 2, gl.FLOAT, false, 0, 0);
                this.program.resolution = gl.getUniformLocation(this.program, "resolution");
                this.program.time = gl.getUniformLocation(this.program, "time");
            }

            render(now = 0) {
                const gl = this.gl;
                gl.clearColor(0, 0, 0, 1);
                gl.clear(gl.COLOR_BUFFER_BIT);
                gl.useProgram(this.program);
                gl.bindBuffer(gl.ARRAY_BUFFER, this.buffer);
                gl.uniform2f(this.program.resolution, this.canvas.width, this.canvas.height);
                gl.uniform1f(this.program.time, now * 0.001);
                gl.drawArrays(gl.TRIANGLE_STRIP, 0, 4);
            }
        }
        </script>
        
        </body>
        </html>
        